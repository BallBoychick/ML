{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression() :\n",
    "      \n",
    "    def __init__( self, learning_rate, iterations, l2_penality ) :\n",
    "          \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations        \n",
    "        self.l2_penality = l2_penality\n",
    "               \n",
    "    def fit( self, X, Y ) :\n",
    "          \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        self.m, self.n = X.shape\n",
    "          \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros( self.n )\n",
    "          \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        Y_pred = self.predict( self.X )\n",
    "          \n",
    "        # calculate gradients      \n",
    "        dW = ( - ( 2 * ( self.X.T ).dot( self.Y - Y_pred ) ) +               \n",
    "               ( 2 * self.l2_penality * self.W ) ) / self.m     \n",
    "        db = - 2 * np.sum( self.Y - Y_pred ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db        \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "    def predict( self, X ) :    \n",
    "        return X.dot( self.W ) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values  5309    NaN\n",
      "15125   NaN\n",
      "23473   NaN\n",
      "dtype: float64\n",
      "Real values       5309     3500.0\n",
      "15125    5450.0\n",
      "23473    3000.0\n",
      "Name: price_usd, dtype: float64\n",
      "Trained W         nan\n",
      "Trained b         -inf\n"
     ]
    }
   ],
   "source": [
    "def main():   \n",
    "    df = pd.read_csv( \"../data/dataset.csv\" )\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    Y = df[\"price_usd\"]\n",
    "    X = df.drop([\"price_usd\"], axis=1)\n",
    "    # X = df.iloc[:, :-1].values\n",
    "    # Y = df.iloc[:, 1].values    \n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \n",
    "                                            \n",
    "                                          test_size = 1 / 3, random_state = 0 )\n",
    "      \n",
    "    # Model training    \n",
    "    model = RidgeRegression( iterations = 1000,                             \n",
    "                            learning_rate = 0.01, l2_penality = 1 )\n",
    "    model.fit( X_train, Y_train )\n",
    "    \n",
    "    Y_pred = model.predict( X_test )    \n",
    "    print( \"Predicted values \", np.round( Y_pred[:3], 2 ) )     \n",
    "    print( \"Real values      \", Y_test[:3] )    \n",
    "    print( \"Trained W        \", round( model.W[0], 2 ) )    \n",
    "    print( \"Trained b        \", round( model.b, 2 ) )\n",
    "if __name__ == \"__main__\" : \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ridge_regression(X, y, alpha=0.9, lambda_value=1, epochs=30):\n",
    "#     \"\"\"\n",
    "#     :param x: feature matrix\n",
    "#     :param y: target vector\n",
    "#     :param alpha: learning rate (default:0.01)\n",
    "#     :param lambda_value: lambda (default:1)\n",
    "#     :param epochs: maximum number of iterations of the\n",
    "#            linear regression algorithm for a single run (default=30)\n",
    "#     :return: weights, list of the cost function changing overtime\n",
    "#     \"\"\"\n",
    " \n",
    "#     m = np.shape(X)[0]  # total number of samples\n",
    "#     n = np.shape(X)[1]  # total number of features\n",
    " \n",
    "#     X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "#     W = np.random.randn(n + 1, )\n",
    " \n",
    "#     # stores the updates on the cost function (loss function)\n",
    "#     cost_history_list = []\n",
    " \n",
    "#     # iterate until the maximum number of epochs\n",
    "#     for current_iteration in range(epochs):  # begin the process\n",
    " \n",
    "#         # compute the dot product between our feature 'X' and weight 'W'\n",
    "#         y_estimated = X.dot(W)\n",
    " \n",
    "#         # calculate the difference between the actual and predicted value\n",
    "#         error = y_estimated - y\n",
    " \n",
    "#         # regularization term\n",
    "#         ridge_reg_term = (lambda_value / 2 * m) * np.sum(np.square(W))\n",
    " \n",
    "#         # calculate the cost (MSE) + regularization term\n",
    "#         cost = (1 / 2 * m) * np.sum(error ** 2) + ridge_reg_term\n",
    " \n",
    "#         # Update our gradient by the dot product between\n",
    "#         # the transpose of 'X' and our error + lambda value * W\n",
    "#         # divided by the total number of samples\n",
    "#         gradient = (1 / m) * (X.T.dot(error) + (lambda_value * W))\n",
    " \n",
    "#         # Now we have to update our weights\n",
    "#         W = W - alpha * gradient\n",
    " \n",
    "#         # Let's print out the cost to see how these values\n",
    "#         # changes after every iteration\n",
    "#         print(f\"cost:{cost} \\t iteration: {current_iteration}\")\n",
    " \n",
    "#         # keep track the cost as it changes in each iteration\n",
    "#         cost_history_list.append(cost)\n",
    " \n",
    "#     return W, cost_history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:1.4771690923884685e+19 \t iteration: 0\n",
      "cost:9.532108353724202e+36 \t iteration: 1\n",
      "cost:6.169697804757955e+54 \t iteration: 2\n",
      "cost:3.993363229780213e+72 \t iteration: 3\n",
      "cost:2.5847213898649407e+90 \t iteration: 4\n",
      "cost:3.7307858661392474e+19 \t iteration: 0\n",
      "cost:2.4121089030243286e+37 \t iteration: 1\n",
      "cost:1.5612477797802205e+55 \t iteration: 2\n",
      "cost:1.010524287196435e+73 \t iteration: 3\n",
      "cost:6.540661567234466e+90 \t iteration: 4\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#     rng = np.random.RandomState(1)\n",
    "#     # x = 15 * rng.rand(50)\n",
    "#     # X = x.reshape(-1, 1)\n",
    " \n",
    "#     # y = 2 * x - 1 + rng.randn(50)\n",
    "\n",
    "#     df = pd.read_csv( \"../data/dataset.csv\" )\n",
    "#     df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#     y = df[\"price_usd\"]\n",
    "#     X = df.drop([\"price_usd\"], axis=1)\n",
    " \n",
    "#     lambda_list = [0.01, 5000]\n",
    " \n",
    "#     for lambda_ in lambda_list:\n",
    "#         # calls ridge regression function with different values of lambda\n",
    "#         weight, _ = ridge_regression(X, y, alpha=0.01,\n",
    "#                                      lambda_value=lambda_, epochs=5)\n",
    " \n",
    "#         fitted_line = np.dot(X, weight[1]) + weight[0]\n",
    "#         # plt.scatter(X, y, label='data points')\n",
    "#         # plt.plot(X, fitted_line, color='r', label='Fitted line')\n",
    "#         # plt.xlabel(\"X\")\n",
    "#         # plt.ylabel(\"y\")\n",
    "#         # plt.title(f\"Ridge Regression (lambda : {lambda_})\")\n",
    "#         # plt.legend()\n",
    "#         # plt.show()\n",
    " \n",
    " \n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4144813e17b6f5f448ed6aaed98153edd3ff37cd658fee1dbd1b201beaf41009"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
